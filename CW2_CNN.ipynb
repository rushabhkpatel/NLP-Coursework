{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Code for Testing Saved Model\n",
    "This file provides a sample to test the saved model. Make necessary changes so that we can test your CNN/RNN model with this file. If you developed a RNN model, change the name of this file to *test_rnn*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data\n",
    "In the sample below, it loads the dev set for testing. But in real marking, the markers will load held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sent1</th>\n",
       "      <th>Sent2</th>\n",
       "      <th>SimScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S., EU Widen Sanctions On Russia</td>\n",
       "      <td>U.S., EU Boost Sanctions On Russia</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The lawyers advised the judges .</td>\n",
       "      <td>The lawyers advised the judges behind the acto...</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Man kills 4 in Calif. before police shoot him ...</td>\n",
       "      <td>Police: Gunman killed 6 in California shootings</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Someone is playing a piano.</td>\n",
       "      <td>A man is playing a guitar.</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In an E-mail statement to the Knoxville News S...</td>\n",
       "      <td>I am not giving any consideration to resignati...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>11493</td>\n",
       "      <td>A man is playing piano.</td>\n",
       "      <td>A man is laying on the ground.</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>11494</td>\n",
       "      <td>The doctors resigned , or the secretaries supp...</td>\n",
       "      <td>The doctors resigned .</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>11495</td>\n",
       "      <td>The artist contacted the banker .</td>\n",
       "      <td>The banker contacted the artist by the student .</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>11496</td>\n",
       "      <td>While the professors arrived , the student wai...</td>\n",
       "      <td>The professors arrived .</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>11497</td>\n",
       "      <td>The banker avoided the author .</td>\n",
       "      <td>The lawyer and the banker avoided the author .</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11498 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Sent1  \\\n",
       "0               0                 U.S., EU Widen Sanctions On Russia   \n",
       "1               1                   The lawyers advised the judges .   \n",
       "2               2  Man kills 4 in Calif. before police shoot him ...   \n",
       "3               3                        Someone is playing a piano.   \n",
       "4               4  In an E-mail statement to the Knoxville News S...   \n",
       "...           ...                                                ...   \n",
       "11493       11493                            A man is playing piano.   \n",
       "11494       11494  The doctors resigned , or the secretaries supp...   \n",
       "11495       11495                  The artist contacted the banker .   \n",
       "11496       11496  While the professors arrived , the student wai...   \n",
       "11497       11497                    The banker avoided the author .   \n",
       "\n",
       "                                                   Sent2  SimScore  \n",
       "0                     U.S., EU Boost Sanctions On Russia      1.00  \n",
       "1      The lawyers advised the judges behind the acto...      0.79  \n",
       "2        Police: Gunman killed 6 in California shootings      0.40  \n",
       "3                             A man is playing a guitar.      0.24  \n",
       "4      I am not giving any consideration to resignati...      0.80  \n",
       "...                                                  ...       ...  \n",
       "11493                     A man is laying on the ground.      0.15  \n",
       "11494                             The doctors resigned .      0.50  \n",
       "11495   The banker contacted the artist by the student .      0.29  \n",
       "11496                           The professors arrived .      0.61  \n",
       "11497     The lawyer and the banker avoided the author .      0.73  \n",
       "\n",
       "[11498 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('cw2_train.csv')\n",
    "dev_data = pd.read_csv('cw2_dev.csv')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings\n",
    "Clearly specify the embeddings your implementation requires. Also provide the link for downloading the embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "<ipython-input-2-1e61666a8f8e>:16: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained glove embeddings\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "\n",
    "embd_name = 'glove.6B.300d'\n",
    "link_to_embd = 'https://archive.org/download/glove.6B.50d-300d/glove.6B.300d.txt' # TODO: you should provide the link to download the embedding here\n",
    "\n",
    "# Below is a sample to load the glove embeddings. ADJUST the code according to the\n",
    "# embedding you want to use. \n",
    "word_vec_dim = 300\n",
    "path_of_downloaded_files = \"E:/RHUL/CW2-Handout/handout/glove.6B.300d.txt\".format(word_vec_dim)\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Functions Needed for Evaluation\n",
    "All functions used to run and evaluate your model should be provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_vec = np.random.rand(word_vec_dim)\n",
    "\n",
    "def get_sent_word_vecs(word_vectors, sent_words):\n",
    "    vecs = []\n",
    "    for ww in sent_words:\n",
    "        if ww in word_vectors:\n",
    "            vecs.append(word_vectors[ww])\n",
    "        else:\n",
    "            vecs.append(oov_vec)\n",
    "    return np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_sent_word_vecs(word_vectors, sent_words):\n",
    "    vecs = []\n",
    "    for ww in sent_words:\n",
    "        if ww in word_vectors:\n",
    "            vecs.append(word_vectors[ww])\n",
    "        else:\n",
    "            vecs.append(oov_vec)\n",
    "    return np.array(vecs)\n",
    "\n",
    "def evaluate_trained_model(trained_model, dev_data):\n",
    "    pred_scores = []\n",
    "    true_scores = []\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "        model.eval()\n",
    "        for i, entry in tqdm(dev_data.iterrows()):\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            gold_score = entry['SimScore']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "            sent1_repr, sent2_repr = trained_model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "        \n",
    "            pred_scores.append(pred_sim)\n",
    "            true_scores.append(gold_score)\n",
    "\n",
    "    assert len(true_scores) == len(pred_scores)\n",
    "    squared_errors = [np.square(ts-ps) for (ts, ps) in zip(true_scores, pred_scores)]\n",
    "    print('MSE of the method on the dev set:', np.mean(squared_errors))\n",
    "\n",
    "    # check the distribution (histo gram) of the squared errors\n",
    "    plt.hist(squared_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Your Model\n",
    "You should provide the implementaiton of your encoder model below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the baseline model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, embd_dim):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.convo1 = nn.Conv1d(in_channels=embd_dim,out_channels=100,kernel_size=1)\n",
    "        self.max_pool = nn.MaxPool1d(1, stride=2)\n",
    "        self.fully_connected_layer = nn.Linear(embd_dim, embd_dim)\n",
    "        \n",
    "    \n",
    "       \n",
    "    def forward(self, sent1_vecs, sent2_vecs):\n",
    "        \n",
    "        def reshape_sent1(a):\n",
    "            return a.reshape(sent1_vecs.shape[0], sent1_vecs.shape[1], 1)\n",
    "         \n",
    "    \n",
    "        def reshape_sent2(a):\n",
    "            return a.reshape(sent2_vecs.shape[0], sent2_vecs.shape[1], 1)\n",
    "        sent1_repr = self.leaky(self.convo1(reshape_sent1(torch.FloatTensor(sent1_vecs))))\n",
    "        sent2_repr = self.leaky(self.convo1(reshape_sent2(torch.FloatTensor(sent2_vecs))))\n",
    "        sent1_repr = self.max_pool(sent1_repr)\n",
    "        sent2_repr = self.max_pool(sent2_repr)\n",
    "       \n",
    "\n",
    "        sent1_repr_1 = self.leaky(self.convo1(reshape_sent1(torch.FloatTensor(sent1_vecs))))\n",
    "        sent2_repr_1 = self.leaky(self.convo1(reshape_sent2(torch.FloatTensor(sent2_vecs))))\n",
    "        sent1_repr_1 = self.max_pool(sent1_repr_1)\n",
    "        sent2_repr_1 = self.max_pool(sent2_repr_1)\n",
    "       \n",
    "\n",
    "        sent1_repr_2 = self.leaky(self.convo1(reshape_sent1(torch.FloatTensor(sent1_vecs))))\n",
    "        sent2_repr_2 = self.leaky(self.convo1(reshape_sent2(torch.FloatTensor(sent2_vecs))))\n",
    "        sent1_repr_2 = self.max_pool(sent1_repr_2)\n",
    "        sent2_repr_2 = self.max_pool(sent2_repr_2)\n",
    "\n",
    "        \n",
    "        \n",
    "        pool_1 = torch.cat([sent1_repr.squeeze(dim=2),sent1_repr_1.squeeze(dim=2),sent1_repr_2.squeeze(dim=2)], dim=1)\n",
    "        pool_2 = torch.cat([sent1_repr.squeeze(dim=2),sent1_repr_1.squeeze(dim=2),sent1_repr_2.squeeze(dim=2)], dim=1)\n",
    "        # Applying Dropout with\n",
    "        pool_1 = self.fully_connected_layer(self.dropout(pool_1))\n",
    "        pool_2 = self.fully_connected_layer(self.dropout(pool_2))\n",
    "             \n",
    "       \n",
    "        return pool_1, pool_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(train_data, n_epochs, lr, optimizer, loss_fnc, model):\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        ep_loss = []\n",
    "        cnt = 0\n",
    "        for i, entry in tqdm(train_data.sample(frac=1).iterrows()):\n",
    "            cnt += 1\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "\n",
    "            # Step 1: Clear the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Step 2: Compute the forward pass of the model\n",
    "            sent1_repr, sent2_repr = model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "            true_sim = torch.FloatTensor([entry['SimScore']])\n",
    "\n",
    "            # Step 3: Compute the loss value that we wish to optimize\n",
    "            loss = loss_fnc(pred_sim, true_sim)\n",
    "            ep_loss.append(loss.detach())\n",
    "\n",
    "            # Step 4: Propagate the loss signal backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 5: Trigger the optimizer to perform one update\n",
    "            optimizer.step()\n",
    "\n",
    "            if  cnt%1000 == 0:\n",
    "                print('epoch {}, avg loss until step {}: {}'.format(epoch_i, cnt, np.mean(ep_loss)))\n",
    "\n",
    "        print('\\n======epoch {} loss======'.format(epoch_i),np.mean(ep_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a7c5b3e0aa4d18b52569a2b61d17ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5635513dacab42c99b9726f9df8eb403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([11])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([24])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 1000: 0.11310171335935593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 2000: 0.1045951396226883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 3000: 0.09898602962493896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 4000: 0.0963294506072998\n",
      "epoch 0, avg loss until step 5000: 0.09390513598918915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 6000: 0.09198470413684845\n",
      "epoch 0, avg loss until step 7000: 0.09105119854211807\n",
      "epoch 0, avg loss until step 8000: 0.08974477648735046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 9000: 0.08859039098024368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\rusha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 10000: 0.08739475905895233\n",
      "epoch 0, avg loss until step 11000: 0.08711204677820206\n",
      "\n",
      "\n",
      "======epoch 0 loss====== 0.08680801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d823cf8d3d034a28bcfc73930511d499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss until step 1000: 0.08253300189971924\n",
      "epoch 1, avg loss until step 2000: 0.0807281956076622\n",
      "epoch 1, avg loss until step 3000: 0.0799618512392044\n",
      "epoch 1, avg loss until step 4000: 0.07910382002592087\n",
      "epoch 1, avg loss until step 5000: 0.07774107903242111\n",
      "epoch 1, avg loss until step 6000: 0.07776038348674774\n",
      "epoch 1, avg loss until step 7000: 0.07768284529447556\n",
      "epoch 1, avg loss until step 8000: 0.07788888365030289\n",
      "epoch 1, avg loss until step 9000: 0.0779138058423996\n",
      "epoch 1, avg loss until step 10000: 0.07791011780500412\n",
      "epoch 1, avg loss until step 11000: 0.07775583863258362\n",
      "\n",
      "\n",
      "======epoch 1 loss====== 0.07779404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb630245388492cbe8f0228cbaa526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, avg loss until step 1000: 0.07237749546766281\n",
      "epoch 2, avg loss until step 2000: 0.07571989297866821\n",
      "epoch 2, avg loss until step 3000: 0.07594526559114456\n",
      "epoch 2, avg loss until step 4000: 0.07482713460922241\n",
      "epoch 2, avg loss until step 5000: 0.07487545907497406\n",
      "epoch 2, avg loss until step 6000: 0.07523693889379501\n",
      "epoch 2, avg loss until step 7000: 0.07507190108299255\n",
      "epoch 2, avg loss until step 8000: 0.07529424130916595\n",
      "epoch 2, avg loss until step 9000: 0.07544352114200592\n",
      "epoch 2, avg loss until step 10000: 0.07554395496845245\n",
      "epoch 2, avg loss until step 11000: 0.07538053393363953\n",
      "\n",
      "\n",
      "======epoch 2 loss====== 0.07536892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a0b49c46da4adb99647c86e7226b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, avg loss until step 1000: 0.07396243512630463\n",
      "epoch 3, avg loss until step 2000: 0.0751955434679985\n",
      "epoch 3, avg loss until step 3000: 0.07450584322214127\n",
      "epoch 3, avg loss until step 4000: 0.07352545112371445\n",
      "epoch 3, avg loss until step 5000: 0.0732509046792984\n",
      "epoch 3, avg loss until step 6000: 0.07342078536748886\n",
      "epoch 3, avg loss until step 7000: 0.07375172525644302\n",
      "epoch 3, avg loss until step 8000: 0.07361449301242828\n",
      "epoch 3, avg loss until step 9000: 0.07410828769207001\n",
      "epoch 3, avg loss until step 10000: 0.07387755066156387\n",
      "epoch 3, avg loss until step 11000: 0.07385565340518951\n",
      "\n",
      "\n",
      "======epoch 3 loss====== 0.07383307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel(word_vec_dim)\n",
    "loss_fnc = nn.MSELoss()\n",
    "\n",
    "# hyper parameters\n",
    "n_epochs = 4 \n",
    "lr = 1e-2 \n",
    "\n",
    "# init optimizer and scheduler (lr adjustor)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr) \n",
    "\n",
    "train_model(train_data, n_epochs, lr, optimizer, loss_fnc, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Evaluate Model\n",
    "The code below creates an instance of the model, loads the saved weights (sample_model.state_dict; run cw2_sample.ipynb will generate this file), and tests it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trained_model(trained_model, dev_data):\n",
    "    pred_scores = []\n",
    "    true_scores = []\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "        for i, entry in tqdm(dev_data.iterrows()):\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            gold_score = entry['SimScore']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "            sent1_repr, sent2_repr = trained_model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "       \n",
    "            pred_scores.append(pred_sim)\n",
    "            true_scores.append(gold_score)\n",
    "\n",
    "    assert len(true_scores) == len(pred_scores)\n",
    "    squared_errors = [np.square(ts-ps) for (ts, ps) in zip(true_scores, pred_scores)]\n",
    "    a = [float(squared_errors[i][0]) for i in range(len(squared_errors))]\n",
    "    print('MSE of the method on the dev set:', np.mean(a))\n",
    "    # check the distribution (histo gram) of the squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b119beef7c4df6b90b97b3b7c3533f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE of the method on the dev set: 0.07644416806479487\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_model(model, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "info_to_save = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'oov_vec': oov_vec\n",
    "}\n",
    "\n",
    "with open('cnn.state_dict', 'wb') as ff:\n",
    "    pickle.dump(info_to_save, ff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
